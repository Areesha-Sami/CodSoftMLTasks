{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "dCVmInrnKu4-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dde28143-07dc-43ff-e657-d12d53c43179"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(rc={'figure.figsize':(18,8)},style='darkgrid')\n",
        "from time import time\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import *\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "train = pd.read_csv(r'/content/drive/MyDrive/Colab Notebooks/train_data.txt',\n",
        "                    sep=':::',names=['Title', 'Genre', 'Description']).reset_index(drop=True)\n",
        "train.head()\n",
        "test = pd.read_csv(r'/content/drive/MyDrive/Colab Notebooks/test_data.txt',\n",
        "                  sep=':::',names=['Title', 'Description']).reset_index(drop=True)\n",
        "test.head()\n",
        "train.describe(include='object').T\n",
        "train.loc[train['Description'].str.contains(r'@\\S+')].head()\n",
        "#We discover that there is more than one language so we need to handle that\n",
        "#First we need to discover different languages\n",
        "def detect_language(text):\n",
        "    try:\n",
        "        #Returning the name 'English instide of en'\n",
        "        return pycountry.languages.get(alpha_2=detect(text)).name.lower()\n",
        "    except:\n",
        "        return 'Unknown'\n",
        "train['Language'] = train['Description'].apply(detect_language)\n",
        "test['Language'] = test['Description'].apply(detect_language)\n",
        "train.head()\n",
        "def clean_text(text):\n",
        "    # Remove strange pattern in different languages if exist\n",
        "    text = re.sub('Mail <svaradi@sprynet.com> for translation. ','',text)\n",
        "    # Remove twitter handles\n",
        "    text = re.sub(r'@\\S+', '', text)\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    # Remove punctuations\n",
        "    text = re.sub(f'[{string.punctuation}]','',text)\n",
        "    # Remove numbers\n",
        "    text = re.sub(f'[{string.digits}]','',text)\n",
        "    # Remove single charachters\n",
        "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
        "\n",
        "    return text\n",
        "  # Using TfidfVectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer(lowercase=True, #Lowercase chars\n",
        "                                   ngram_range=(1,1), #Capture only single words in each text(unigrams)\n",
        "                                   stop_words='english',#Remove stop_words\n",
        "                                   min_df=2)#Ignore words that appears less than 2 times\n",
        "x_train = tfidf_vectorizer.fit_transform(train['Description'])\n",
        "x_test = tfidf_vectorizer.transform(test['Description'])\n",
        "sampler = RandomOverSampler()\n",
        "#We will pass to it the output of TfidfVectorizer from train data\n",
        "x_train_resampled , y_train_resampled = sampler.fit_resample(x_train,train['Genre'])\n",
        "sns.countplot(data=y_train_resampled,x=y_train_resampled.values,palette='rocket')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "print('Train :',x_train_resampled.shape[0])\n",
        "print('Test :',y_train_resampled.shape[0])\n",
        "NB = MultinomialNB(alpha=0.3)\n",
        "start_time = time()\n",
        "NB.fit(x_train_resampled,y_train_resampled)\n",
        "y_pred = NB.predict(x_test)\n",
        "print('Accuracy :',accuracy_score(y_actual,y_pred))\n",
        "end_time = time()\n",
        "print('Running Time : ',round(end_time - start_time,2),'Secounds')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "SnsGRxA36sXY",
        "outputId": "e7a841c6-e50b-4f63-9d7e-d3f3bffe0c5c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-d2d25e69af16>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangdetect\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdetect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpycountry\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mover_sampling\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomOverSampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langdetect'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}